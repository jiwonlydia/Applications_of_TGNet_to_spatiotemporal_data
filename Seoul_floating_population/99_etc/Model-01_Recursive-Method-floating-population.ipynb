{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef9e6a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import random\n",
    "import math\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Conv2D, AveragePooling2D, Conv2DTranspose, Activation\n",
    "from keras.layers import concatenate, BatchNormalization, Dropout, Add, RepeatVector, Reshape\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "#from tensorflow.keras.optimizers import SGD , Adam\n",
    "from keras.optimizers import SGD , Adam\n",
    "# from keras.utils.training_utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9382dd3",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "985c1986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='')\n",
    "\n",
    "parser.add_argument('--lr', type=float, default=0.001)\n",
    "parser.add_argument('--decay', type=float, default=0.01)\n",
    "parser.add_argument('--batch', type=int, default=128)\n",
    "parser.add_argument('--epoch', type=int, default=10000)\n",
    "parser.add_argument('--drop_p', type=float, default=0.1)\n",
    "parser.add_argument('--reg', type=float, default=0.0)\n",
    "parser.add_argument('--test', action='store_true')\n",
    "\n",
    "parser.add_argument('--output_dir', type=str, default='./output/')\n",
    "parser.add_argument('--save_dir', type=str, default='./model_saved/')\n",
    "parser.add_argument('--model_name', type=str, default='no_named')\n",
    "\n",
    "parser.add_argument('--scale', type=str, default='min_max')\n",
    "parser.add_argument('--dataset_name', type=str, default='NYC')\n",
    "parser.add_argument('--thr', type=int, default=10)\n",
    "parser.add_argument('--alpha', type=float, default=0.05)\n",
    "parser.add_argument('--num_gpu', type=int, default=1)\n",
    "# parser.add_argument('--coord', type=float, default=25.0)\n",
    "# parser.add_argument('--coord_net', type=int, default=2)\n",
    "\n",
    "parser.add_argument('--temp', type=int, default=16)\n",
    "parser.add_argument('--nf', type=int, default=32)\n",
    "parser.add_argument('--enf', type=int, default=64)\n",
    "parser.add_argument('--patience', type=int, default=100)\n",
    "parser.add_argument('--es', type=str, default='min')\n",
    "\n",
    "args, extras = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df60659",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ea7719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_np_data(filename):\n",
    "    try:\n",
    "        data = np.load(filename)['arr_0']\n",
    "        print(\"[*] Success to load \", filename)\n",
    "        return data\n",
    "    except:\n",
    "        raise IOError(\"Fail to load data\", filename)\n",
    "\n",
    "def get_min_max(data, scale='min_max'):\n",
    "    if scale=='min_max':\n",
    "        return np.min(data), np.max(data)\n",
    "    else:\n",
    "        return None, None\n",
    "    \n",
    "def min_max(data, min_value, max_value):\n",
    "    result = data - min_value\n",
    "    scale = max_value - min_value\n",
    "    assert scale > 0\n",
    "    result = result/scale\n",
    "    return result\n",
    "\n",
    "def scaler(data, scale_type='log', inv=False, min_value=None, max_value=None):\n",
    "    if scale_type == 'log':\n",
    "        if not inv:\n",
    "            print(\"[*] \", np.shape(data), \":log scaled\")\n",
    "            return logscale(data)\n",
    "        else:\n",
    "            print(\"[*] \", np.shape(data), \": inverse log scaled\")\n",
    "            return inverse_logscale(data)\n",
    "    elif scale_type == 'min_max':\n",
    "        assert (min_value != None) and (max_value != None)\n",
    "        if not inv:\n",
    "            return min_max(data, min_value, max_value)\n",
    "        else:\n",
    "            return inverse_min_max(data, min_value, max_value)\n",
    "    else:\n",
    "        print(\"[!] invalid scale type: \", scale_type)\n",
    "        raise\n",
    "        \n",
    "def inverse_min_max(data, min_value, max_value):\n",
    "    scale = max_value - min_value\n",
    "    result = scale * data + min_value\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00ffb6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadData(STAMP, LAG, STEP, train=True, valid=False):\n",
    "    \n",
    "#     args.model_name = f'SeoulFloatingPop_lag{LAG}_step{STEP}'\n",
    "\n",
    "    ### train set\n",
    "\n",
    "    x_train = load_np_data(f'./data/x_train_stamp{STAMP}_lag{LAG}.npz')\n",
    "    min_x, max_x = get_min_max(x_train, 'min_max')\n",
    "\n",
    "    if train:    \n",
    "        y_train = load_np_data(f'./data/y_train_stamp{STAMP}_lag{LAG}.npz')\n",
    "        temporal_train = load_np_data(f'./data/temporal_train_stamp{STAMP}_lag{LAG}.npz')\n",
    "        temporal_train = temporal_train.reshape(temporal_train.shape[0],temporal_train.shape[2])\n",
    "        \n",
    "        # Min Max Scaling\n",
    "        x_train = scaler(x_train, 'min_max', inv=False, min_value=min_x, max_value=max_x)\n",
    "        y_train = scaler(y_train, 'min_max', inv=False, min_value=min_x, max_value=max_x)\n",
    "        \n",
    "        ### validation set\n",
    "        valid_ratio=0.2\n",
    "        num_train = int(len(x_train)*(1.0-valid_ratio))\n",
    "        x_train, x_valid = x_train[:num_train], x_train[num_train:]\n",
    "        temporal_train, temporal_valid = temporal_train[:num_train], temporal_train[num_train:]\n",
    "        y_train, y_valid = y_train[:num_train], y_train[num_train:]\n",
    "        \n",
    "        if valid:\n",
    "            \n",
    "            print(f'x_valid.shape = {x_valid.shape}')\n",
    "            print(f'y_valid.shape = {y_valid.shape}')\n",
    "            print(f'temporal_valid.shape = {temporal_valid.shape}')\n",
    "        \n",
    "            return x_valid, temporal_valid, y_valid\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            print('--- training dataset ---')\n",
    "            print(f'x_train.shape = {x_train.shape}')\n",
    "            print(f'y_train.shape = {y_train.shape}')\n",
    "            print(f'temporal_train.shape = {temporal_train.shape}')\n",
    "\n",
    "            return x_train, temporal_train, y_train\n",
    "    \n",
    "    else: ### test set\n",
    "\n",
    "        x_test = load_np_data(f'./data/x_test_stamp{STAMP}_lag{LAG}_step{STEP}.npz')\n",
    "        y_test = load_np_data(f'./data/y_test_stamp{STAMP}_lag{LAG}_step{STEP}.npz')\n",
    "        temporal_test = load_np_data(f'./data/temporal_test_stamp{STAMP}_lag{LAG}_step{STEP}.npz')\n",
    "\n",
    "        # Min Max Scaling\n",
    "        x_test = scaler(x_test, 'min_max', inv=False, min_value=min_x, max_value=max_x)\n",
    "        y_test = scaler(y_test, 'min_max', inv=False, min_value=min_x, max_value=max_x)\n",
    "\n",
    "        print('--- test dataset ---')\n",
    "        print(f'x_test.shape = {x_test.shape}')\n",
    "        print(f'y_test.shape = {y_test.shape}')\n",
    "        print(f'temporal_test.shape = {temporal_test.shape}')\n",
    "\n",
    "        return x_test, temporal_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aed9907",
   "metadata": {},
   "source": [
    "# TGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "343db561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    rtn = np.sqrt(  np.average( np.square(y_pred-y_true) ) )\n",
    "    return  rtn\n",
    "\n",
    "def mape(y_true,y_pred):\n",
    "    rtn = np.mean(np.abs((y_true - y_pred) / (1.0+y_true)))\n",
    "    return rtn\n",
    "\n",
    "def mape_trs(y_true,y_pred, trs=0):\n",
    "    true_mask = y_true > trs\n",
    "    tmp_abs = np.divide(np.abs(y_true-y_pred)[true_mask] , y_true[true_mask])\n",
    "\n",
    "    rtn = (np.average(tmp_abs))\n",
    "    return rtn\n",
    "\n",
    "def rmse_trs(y_true,y_pred, trs=0):\n",
    "    true_mask = y_true > trs\n",
    "    tmp_abs = np.sqrt(np.average(np.square(y_pred-y_true)[true_mask]))\n",
    "    return tmp_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10ce0634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gn_block(input, num_c=64, kernel_size=(3,3), strides=(1,1), padding='SAME', activation='relu', dropout=None, regularizer=0.01):\n",
    "    net = AveragePooling2D(kernel_size, strides, padding)(input)\n",
    "    net = Conv2D(num_c, kernel_size=(1,1), strides=strides, activation='linear', padding=padding, kernel_regularizer=regularizers.l1(regularizer))(net)\n",
    "\n",
    "    net_sf = Conv2D(num_c, kernel_size=(1,1), strides=strides, activation='linear', padding=padding, kernel_regularizer=regularizers.l1(regularizer))(input)\n",
    "\n",
    "    net = Add()([net, net_sf])\n",
    "    net = concatenate([input, net])\n",
    "    net = Conv2D(num_c, kernel_size=(1,1), strides=strides, activation=activation, padding=padding, kernel_regularizer=regularizers.l1(regularizer))(net)\n",
    "    net = BatchNormalization()(net)\n",
    "\n",
    "    if dropout == None:\n",
    "        return net\n",
    "    else:\n",
    "        net = Dropout(dropout)(net)\n",
    "        return net\n",
    "\n",
    "def deconv_block(input, num_c=64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', dropout=None, regularizer=0.01):\n",
    "    net = Conv2DTranspose(num_c, kernel_size=kernel_size, strides=strides, activation=activation, padding=padding, kernel_regularizer=regularizers.l1(regularizer))(input)\n",
    "    net = BatchNormalization()(net)\n",
    "    if dropout == None:\n",
    "        return net\n",
    "    else:\n",
    "        net = Dropout(dropout)(net)\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "277b5465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TGNet(input_shape):\n",
    "    nf = args.nf\n",
    "    h,w = input_shape[:2]\n",
    "    start_input = Input(shape=input_shape)\n",
    "    temporal_input = Input(shape=(55,))\n",
    "    input_tensors = [start_input, temporal_input]\n",
    "\n",
    "\n",
    "    ### Temporal guided embedding\n",
    "    net_temp = Dense(args.temp, activation='relu')(temporal_input)\n",
    "    # self.net_temp = Dense(args.temp, activation='relu')(net_temp)\n",
    "    net_temp = RepeatVector(h*w)(net_temp)\n",
    "    net_temp = Reshape((h,w,args.temp))(net_temp)\n",
    "\n",
    "    ### U-net layers\n",
    "    net1 = concatenate([start_input, net_temp], axis=-1)\n",
    "    net1 = gn_block(net1, nf, dropout=args.drop_p,regularizer=args.reg)\n",
    "    net11 = AveragePooling2D(pool_size=(2,2))(net1)\n",
    "    net2 = gn_block(net11, nf*2,  dropout=args.drop_p, regularizer=args.reg)\n",
    "    net3 = gn_block(net2, nf*2,  dropout=args.drop_p, regularizer=args.reg)\n",
    "    net33 = concatenate([net2, net3])\n",
    "    net4 = gn_block(net33, nf*2,  dropout=args.drop_p, regularizer=args.reg)\n",
    "    net4 = concatenate([net2, net3, net4])\n",
    "\n",
    "    net5 = deconv_block(net4, nf*4, (2,2), (2,2),   dropout=args.drop_p,regularizer=args.reg)\n",
    "    net5 = concatenate([net5, net1])\n",
    "    net6 = deconv_block(net5, nf*4, (3,3), (1,1), 'same',  dropout=args.drop_p, regularizer=args.reg)\n",
    "\n",
    "    ## Position-wise Regression\n",
    "    net7 = concatenate([net6, start_input, net_temp], axis=-1)\n",
    "    net7 = gn_block(net7, nf*4, kernel_size=(1,1), dropout=args.drop_p, regularizer=args.reg)\n",
    "\n",
    "    output = Conv2D(1, kernel_size=(1,1), padding='same', kernel_regularizer=regularizers.l2(args.reg))(net7)\n",
    "    output = Activation('relu')(output)\n",
    "\n",
    "    model = Model(inputs=input_tensors, outputs=output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ce14749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(STAMP, LAG, STEP):\n",
    "\n",
    "    x_train, temporal_train, y_train = LoadData(STAMP=STAMP, LAG=LAG, STEP=STEP, train=True, valid=False)\n",
    "    x_valid, temporal_valid, y_valid = LoadData(STAMP=STAMP, LAG=LAG, STEP=STEP, train=True, valid=True)\n",
    "\n",
    "    input_shape = [10, 20, LAG]\n",
    "    model = TGNet(input_shape)\n",
    "\n",
    "    model.compile(loss=['mean_absolute_error'], \n",
    "               optimizer=Adam(lr=args.lr, decay=args.decay), \n",
    "               metrics=['mean_absolute_error'])\n",
    "\n",
    "    \n",
    "    print('===== START TRAINGING =====')\n",
    "    \n",
    "    \n",
    "    best_eval_loss = 100000\n",
    "    patience = 0\n",
    "\n",
    "    for idx in range(args.epoch): # epoch\n",
    "        if idx%100 == 0:\n",
    "            print(f'Epoch = {idx}')\n",
    "        with tf.device('/GPU:1'):    \n",
    "            model.fit([x_train, temporal_train], y_train, \n",
    "                      batch_size=args.batch, epochs=1, shuffle=True, verbose=0)\n",
    "\n",
    "            eval_loss = model.evaluate([x_valid, temporal_valid], y_valid, \n",
    "                                       batch_size=args.batch, verbose=0)\n",
    "        patience += 1\n",
    "        if patience > args.patience:\n",
    "            print(f'Epoch = {idx}, patience reached {args.patience}')\n",
    "            break\n",
    "\n",
    "        if best_eval_loss > eval_loss[-1]:\n",
    "            if not os.path.exists('./model_saved'):\n",
    "                os.mkdir('./model_saved')\n",
    "            else:\n",
    "                model.save(f'./model_saved/best_model_stamp{STAMP}_lag{LAG}.h5')\n",
    "\n",
    "            best_eval_loss = eval_loss[-1]\n",
    "            patience = 0\n",
    "    print('===== END TRAINGING =====')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb0856a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_result(data):\n",
    "    num_row, h, w = data.shape[:3]\n",
    "    num_col = int(h*w)\n",
    "    return np.reshape(data, [num_row, num_col])\n",
    "\n",
    "def save_test_output(pred_inverse, y_inverse, output_path=None):\n",
    "    num_row, h, w = pred_inverse.shape[:3]\n",
    "    num_col = int(h*w)\n",
    "    assert pred_inverse.shape[:3] == y_inverse.shape[:3]\n",
    "    if output_path == None:\n",
    "        output_path = './model_output/temporal_directory'\n",
    "        print(\"[!] Please Assign Output Path in Arguments\")\n",
    "\n",
    "    np_pred = flatten_result(pred_inverse) #np.reshape(pred_inverse, [num_row, num_col])\n",
    "    np_y = flatten_result(y_inverse) #np.reshape(y_inverse, [num_row, num_col])\n",
    "\n",
    "    col_name = ['col_'+str(i) for i in range(0, num_col)]\n",
    "    index = np.arange(0, num_row)\n",
    "    df_pred = pd.DataFrame(np_pred, columns=col_name, index=index)\n",
    "    df_y = pd.DataFrame(np_y, columns=col_name, index=index)\n",
    "\n",
    "    df_y.to_csv(output_path+'_gt.csv', index=False)\n",
    "    df_pred.to_csv(output_path+'_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c6b1b0",
   "metadata": {},
   "source": [
    "# Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88619ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_step_forecast(STAMP, LAG):\n",
    "    # Load saved model\n",
    "    with tf.device('/GPU:1'):\n",
    "        model = tf.keras.models.load_model(f'./model_saved/best_model_stamp{STAMP}_lag{LAG}.h5')\n",
    "    print(f'Model Loaded: best_model_stamp{STAMP}_lag{LAG}.h5')\n",
    "    \n",
    "    min_x, max_x = get_min_max(load_np_data(f'./data/x_train_stamp{STAMP}_lag{LAG}.npz'), 'min_max')\n",
    "    x_test, temporal_test, y_test = LoadData(STAMP=STAMP, LAG=LAG, STEP=1, train=False, valid=False)\n",
    "    \n",
    "    temporal_test_step1 = temporal_test[:,0,:]\n",
    "    with tf.device('/GPU:1'):\n",
    "        y_pred =  model.predict([x_test, temporal_test_step1]) ; print(y_pred.sum())\n",
    "    y_true = np.expand_dims(y_test[:,:,:,0], axis=-1)\n",
    "    y_pred_inv = scaler(y_pred, 'min_max', inv=True, min_value=min_x, max_value=max_x)\n",
    "    y_true_inv = scaler(y_true, 'min_max', inv=True, min_value=min_x, max_value=max_x)    \n",
    "    RMSE = rmse(y_true_inv, y_pred_inv)\n",
    "    save_test_output(y_pred_inv, y_true_inv, output_path=f'./output/predictions/stamp{STAMP}_lag{LAG}_step1')\n",
    "    print(RMSE)\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e638eef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_step_forecast(STAMP, LAG, STEP):\n",
    "    \n",
    "    # Load saved model\n",
    "    with tf.device('/GPU:1'):\n",
    "        model = tf.keras.models.load_model(f'./model_saved/best_model_stamp{STAMP}_lag{LAG}.h5')\n",
    "    print(f'Model Loaded: best_model_stamp{STAMP}_lag{LAG}.h5')\n",
    "    min_x, max_x = get_min_max(load_np_data(f'./data/x_train_stamp{STAMP}_lag{LAG}.npz'), 'min_max')\n",
    "    x_test, temporal_test, y_test = LoadData(STAMP=STAMP, LAG=LAG, STEP=STEP, train=False, valid=False)\n",
    "\n",
    "    rmse_list = []\n",
    "\n",
    "    # Single-Step Forecast\n",
    "    temporal_test_step1 = temporal_test[:,0,:]\n",
    "    with tf.device('/GPU:1'):\n",
    "        y_pred =  model.predict([x_test, temporal_test_step1])\n",
    "    y_true = np.expand_dims(y_test[:,:,:,0], axis=-1)\n",
    "\n",
    "    y_pred_inv = scaler(y_pred, 'min_max', inv=True, min_value=min_x, max_value=max_x)\n",
    "    y_true_inv = scaler(y_true, 'min_max', inv=True, min_value=min_x, max_value=max_x)    \n",
    "    save_test_output(y_pred_inv, y_true_inv, output_path=f'./output/predictions/stamp{STAMP}_lag{LAG}_step1')\n",
    "    \n",
    "    RMSE = rmse(y_true_inv, y_pred_inv)\n",
    "    rmse_list.append(RMSE)\n",
    "    print(f'RMSE of Single-Step Forecast = {RMSE:3.3f}')\n",
    "\n",
    "    y_pred_new = y_pred\n",
    "    for h in range(2, STEP+1):\n",
    "\n",
    "        # Multi-Step Forecast (h-step)\n",
    "        temporal_test_h = temporal_test[:,h-1,:]\n",
    "        if h > LAG:\n",
    "            x_test_new = y_pred_new[:,:,:,h-LAG-1:h-1]\n",
    "        else:\n",
    "            x_test_new = np.concatenate([x_test[:,:,:,h-1:], y_pred_new], axis=-1)\n",
    "        print(x_test_new.shape)\n",
    "        with tf.device('/GPU:1'):\n",
    "            y_pred = model.predict([x_test_new, temporal_test_h])\n",
    "        y_pred_new = np.concatenate([y_pred_new, y_pred], axis=-1)\n",
    "        y_true = np.expand_dims(y_test[:,:,:,h-1], axis=-1)\n",
    "\n",
    "        y_pred_inv = scaler(y_pred, 'min_max', inv=True, min_value=min_x, max_value=max_x)\n",
    "        y_true_inv = scaler(y_true, 'min_max', inv=True, min_value=min_x, max_value=max_x)\n",
    "        save_test_output(y_pred_inv, y_true_inv, output_path=f'./output/predictions/stamp{STAMP}_lag{LAG}_step{h}')\n",
    "        RMSE = rmse(y_true_inv, y_pred_inv)\n",
    "        rmse_list.append(RMSE)\n",
    "        print(f'RMSE of {h}-Step Forecast = {RMSE:3.3f}')\n",
    "        \n",
    "        if not os.path.exists('./output/metric'):\n",
    "            os.mkdir('./output/metric')\n",
    "        index = np.arange(0, len(rmse_list))\n",
    "        df_rmse = pd.DataFrame(rmse_list, columns=['RMSE'], index=index)\n",
    "        df_rmse.to_csv('./output/metric/' + f'rmse_stamp{STAMP}_lag{LAG}_step{STEP}.csv')\n",
    "        \n",
    "    print('#'*57)\n",
    "    print(f'###  RMSE of STAMP {STAMP} LAG {LAG} STEP {STEP} = {rmse_list[-1]} ###')\n",
    "    print('#'*57)\n",
    "\n",
    "    return rmse_list[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4be8a0",
   "metadata": {},
   "source": [
    "# 24H ahead forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c888dc27",
   "metadata": {},
   "source": [
    "### Tuning the time unit of training data (Recursive Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed9e2c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.epoch = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6bfc672",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAMP=1, LAG=2, STEP=48\n",
      "Model Loaded: best_model_stamp1_lag2.h5\n",
      "[*] Success to load  ./data/x_train_stamp1_lag2.npz\n",
      "[*] Success to load  ./data/x_train_stamp1_lag2.npz\n",
      "[*] Success to load  ./data/x_test_stamp1_lag2_step48.npz\n",
      "[*] Success to load  ./data/y_test_stamp1_lag2_step48.npz\n",
      "[*] Success to load  ./data/temporal_test_stamp1_lag2_step48.npz\n",
      "--- test dataset ---\n",
      "x_test.shape = (1390, 10, 20, 2)\n",
      "y_test.shape = (1390, 10, 20, 48)\n",
      "temporal_test.shape = (1390, 48, 55)\n",
      "44/44 [==============================] - 1s 5ms/step\n",
      "RMSE of Single-Step Forecast = 11.560\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "RMSE of 2-Step Forecast = 15.095\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 3-Step Forecast = 19.264\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 4-Step Forecast = 23.022\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "RMSE of 5-Step Forecast = 27.032\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 6-Step Forecast = 31.236\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 7-Step Forecast = 35.749\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 8-Step Forecast = 40.550\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 9-Step Forecast = 45.543\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 10-Step Forecast = 50.874\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 11-Step Forecast = 56.615\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 12-Step Forecast = 62.469\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 13-Step Forecast = 68.462\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 14-Step Forecast = 74.795\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 15-Step Forecast = 81.301\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 16-Step Forecast = 87.855\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "RMSE of 17-Step Forecast = 94.476\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "RMSE of 18-Step Forecast = 101.137\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 19-Step Forecast = 107.585\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 20-Step Forecast = 114.272\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 21-Step Forecast = 120.797\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 22-Step Forecast = 127.065\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 23-Step Forecast = 132.964\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 24-Step Forecast = 138.516\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 25-Step Forecast = 143.759\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 26-Step Forecast = 148.886\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 27-Step Forecast = 153.974\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 28-Step Forecast = 159.110\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 29-Step Forecast = 163.777\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 30-Step Forecast = 168.034\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "RMSE of 31-Step Forecast = 172.204\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 32-Step Forecast = 177.118\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "RMSE of 33-Step Forecast = 181.587\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 34-Step Forecast = 185.659\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 35-Step Forecast = 189.633\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 36-Step Forecast = 193.125\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 37-Step Forecast = 196.990\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 38-Step Forecast = 200.568\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 39-Step Forecast = 203.978\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 40-Step Forecast = 207.434\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 41-Step Forecast = 211.107\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 42-Step Forecast = 214.517\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 43-Step Forecast = 217.610\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "RMSE of 44-Step Forecast = 220.668\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 45-Step Forecast = 223.823\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 46-Step Forecast = 227.056\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "RMSE of 47-Step Forecast = 230.639\n",
      "(1390, 10, 20, 2)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 48-Step Forecast = 234.067\n",
      "#########################################################\n",
      "###  RMSE of STAMP 1 LAG 2 STEP 48 = 234.06677691154528 ###\n",
      "#########################################################\n",
      "STAMP=1, LAG=4, STEP=48\n",
      "Model Loaded: best_model_stamp1_lag4.h5\n",
      "[*] Success to load  ./data/x_train_stamp1_lag4.npz\n",
      "[*] Success to load  ./data/x_train_stamp1_lag4.npz\n",
      "[*] Success to load  ./data/x_test_stamp1_lag4_step48.npz\n",
      "[*] Success to load  ./data/y_test_stamp1_lag4_step48.npz\n",
      "[*] Success to load  ./data/temporal_test_stamp1_lag4_step48.npz\n",
      "--- test dataset ---\n",
      "x_test.shape = (1388, 10, 20, 4)\n",
      "y_test.shape = (1388, 10, 20, 48)\n",
      "temporal_test.shape = (1388, 48, 55)\n",
      "44/44 [==============================] - 1s 8ms/step\n",
      "RMSE of Single-Step Forecast = 5.751\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 2-Step Forecast = 7.335\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 3-Step Forecast = 8.732\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "RMSE of 4-Step Forecast = 9.789\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "RMSE of 5-Step Forecast = 10.716\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 6-Step Forecast = 11.544\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 7-Step Forecast = 12.285\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "RMSE of 8-Step Forecast = 12.960\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "RMSE of 9-Step Forecast = 13.578\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "RMSE of 10-Step Forecast = 14.155\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "RMSE of 11-Step Forecast = 14.708\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "RMSE of 12-Step Forecast = 15.263\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 13-Step Forecast = 15.813\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "RMSE of 14-Step Forecast = 16.329\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 15-Step Forecast = 16.816\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 16-Step Forecast = 17.269\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 17-Step Forecast = 17.685\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 18-Step Forecast = 18.076\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 19-Step Forecast = 18.437\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 20-Step Forecast = 18.767\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 21-Step Forecast = 19.081\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 22-Step Forecast = 19.385\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 23-Step Forecast = 19.686\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 24-Step Forecast = 19.996\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 25-Step Forecast = 20.316\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 26-Step Forecast = 20.615\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 27-Step Forecast = 20.860\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "RMSE of 28-Step Forecast = 21.062\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "RMSE of 29-Step Forecast = 21.216\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "RMSE of 30-Step Forecast = 21.318\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "RMSE of 31-Step Forecast = 21.380\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "RMSE of 32-Step Forecast = 21.403\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "RMSE of 33-Step Forecast = 21.397\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "RMSE of 34-Step Forecast = 21.356\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "RMSE of 35-Step Forecast = 21.290\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "RMSE of 36-Step Forecast = 21.231\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 37-Step Forecast = 21.195\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 38-Step Forecast = 21.186\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 39-Step Forecast = 21.192\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 40-Step Forecast = 21.246\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 41-Step Forecast = 21.324\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 42-Step Forecast = 21.428\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 43-Step Forecast = 21.520\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 44-Step Forecast = 21.594\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 45-Step Forecast = 21.678\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 46-Step Forecast = 21.773\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 47-Step Forecast = 21.868\n",
      "(1388, 10, 20, 4)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 48-Step Forecast = 21.962\n",
      "#########################################################\n",
      "###  RMSE of STAMP 1 LAG 4 STEP 48 = 21.96181205421239 ###\n",
      "#########################################################\n",
      "STAMP=1, LAG=6, STEP=48\n",
      "Model Loaded: best_model_stamp1_lag6.h5\n",
      "[*] Success to load  ./data/x_train_stamp1_lag6.npz\n",
      "[*] Success to load  ./data/x_train_stamp1_lag6.npz\n",
      "[*] Success to load  ./data/x_test_stamp1_lag6_step48.npz\n",
      "[*] Success to load  ./data/y_test_stamp1_lag6_step48.npz\n",
      "[*] Success to load  ./data/temporal_test_stamp1_lag6_step48.npz\n",
      "--- test dataset ---\n",
      "x_test.shape = (1386, 10, 20, 6)\n",
      "y_test.shape = (1386, 10, 20, 48)\n",
      "temporal_test.shape = (1386, 48, 55)\n",
      "44/44 [==============================] - 1s 9ms/step\n",
      "RMSE of Single-Step Forecast = 5.781\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "RMSE of 2-Step Forecast = 7.400\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 3-Step Forecast = 8.733\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 4-Step Forecast = 9.695\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 5-Step Forecast = 10.583\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "RMSE of 6-Step Forecast = 11.406\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 7-Step Forecast = 12.202\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 8-Step Forecast = 12.932\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 9-Step Forecast = 13.598\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "RMSE of 10-Step Forecast = 14.208\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 11-Step Forecast = 14.792\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 12-Step Forecast = 15.390\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 13-Step Forecast = 15.971\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 14-Step Forecast = 16.524\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 15-Step Forecast = 17.026\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 16-Step Forecast = 17.492\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 17-Step Forecast = 17.930\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 18-Step Forecast = 18.334\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 19-Step Forecast = 18.730\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 20-Step Forecast = 19.114\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 21-Step Forecast = 19.486\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 22-Step Forecast = 19.852\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 23-Step Forecast = 20.219\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 24-Step Forecast = 20.567\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 25-Step Forecast = 20.910\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 26-Step Forecast = 21.212\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 27-Step Forecast = 21.493\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 28-Step Forecast = 21.740\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 29-Step Forecast = 21.953\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "RMSE of 30-Step Forecast = 22.130\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 31-Step Forecast = 22.259\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 32-Step Forecast = 22.353\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 33-Step Forecast = 22.415\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 34-Step Forecast = 22.447\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 35-Step Forecast = 22.481\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 36-Step Forecast = 22.535\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 5ms/step\n",
      "RMSE of 37-Step Forecast = 22.612\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 38-Step Forecast = 22.690\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 39-Step Forecast = 22.798\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 40-Step Forecast = 22.915\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 41-Step Forecast = 23.049\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 42-Step Forecast = 23.173\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 43-Step Forecast = 23.287\n",
      "(1386, 10, 20, 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 44-Step Forecast = 23.395\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 45-Step Forecast = 23.502\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 46-Step Forecast = 23.597\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 47-Step Forecast = 23.690\n",
      "(1386, 10, 20, 6)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 48-Step Forecast = 23.772\n",
      "#########################################################\n",
      "###  RMSE of STAMP 1 LAG 6 STEP 48 = 23.771598925488437 ###\n",
      "#########################################################\n",
      "STAMP=1, LAG=8, STEP=48\n",
      "Model Loaded: best_model_stamp1_lag8.h5\n",
      "[*] Success to load  ./data/x_train_stamp1_lag8.npz\n",
      "[*] Success to load  ./data/x_train_stamp1_lag8.npz\n",
      "[*] Success to load  ./data/x_test_stamp1_lag8_step48.npz\n",
      "[*] Success to load  ./data/y_test_stamp1_lag8_step48.npz\n",
      "[*] Success to load  ./data/temporal_test_stamp1_lag8_step48.npz\n",
      "--- test dataset ---\n",
      "x_test.shape = (1384, 10, 20, 8)\n",
      "y_test.shape = (1384, 10, 20, 48)\n",
      "temporal_test.shape = (1384, 48, 55)\n",
      "44/44 [==============================] - 1s 7ms/step\n",
      "RMSE of Single-Step Forecast = 5.721\n",
      "(1384, 10, 20, 8)\n",
      "44/44 [==============================] - 0s 6ms/step\n",
      "RMSE of 2-Step Forecast = 7.288\n",
      "(1384, 10, 20, 8)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 3-Step Forecast = 8.612\n",
      "(1384, 10, 20, 8)\n",
      "44/44 [==============================] - 0s 7ms/step\n",
      "RMSE of 4-Step Forecast = 9.576\n",
      "(1384, 10, 20, 8)\n",
      " 9/44 [=====>........................] - ETA: 0s[*] Success to load  ./data/x_train_stamp1_lag8.npz\n",
      "[*] Success to load  ./data/y_train_stamp1_lag8.npz\n",
      "[*] Success to load  ./data/temporal_train_stamp1_lag8.npz\n",
      "--- training dataset ---\n",
      "x_train.shape = (3448, 10, 20, 8)\n",
      "y_train.shape = (3448, 10, 20, 1)\n",
      "temporal_train.shape = (3448, 55)\n",
      "[*] Success to load  ./data/x_train_stamp1_lag8.npz\n",
      "[*] Success to load  ./data/y_train_stamp1_lag8.npz\n",
      "[*] Success to load  ./data/temporal_train_stamp1_lag8.npz\n",
      "x_valid.shape = (863, 10, 20, 8)\n",
      "y_valid.shape = (863, 10, 20, 1)\n",
      "temporal_valid.shape = (863, 55)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpark/miniconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== START TRAINGING =====\n",
      "Epoch = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ScopedTFGraph.__del__ at 0x7f0fc0198f70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jpark/miniconda3/lib/python3.8/site-packages/tensorflow/python/framework/c_api_util.py\", line 55, in __del__\n",
      "    self.deleter(self.graph)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m     table[i,j] \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_forecast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSTAMP\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstamp_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLAG\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlag_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSTEP\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mmulti_step_forecast\u001b[0;34m(STAMP, LAG, STEP)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/GPU:1\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 37\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_test_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemporal_test_h\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m y_pred_new \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([y_pred_new, y_pred], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/engine/training.py:2033\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2032\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m-> 2033\u001b[0m tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     table[i,j] \u001b[38;5;241m=\u001b[39m multi_step_forecast(STAMP\u001b[38;5;241m=\u001b[39mstamp_list[i], LAG\u001b[38;5;241m=\u001b[39mlag_list[j], STEP\u001b[38;5;241m=\u001b[39mstep_list[i])\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m---> 15\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSTAMP\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstamp_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLAG\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlag_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSTEP\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     table[i,j] \u001b[38;5;241m=\u001b[39m multi_step_forecast(STAMP\u001b[38;5;241m=\u001b[39mstamp_list[i], LAG\u001b[38;5;241m=\u001b[39mlag_list[j], STEP\u001b[38;5;241m=\u001b[39mstep_list[i])\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(STAMP, LAG, STEP)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/GPU:1\u001b[39m\u001b[38;5;124m'\u001b[39m):    \n\u001b[0;32m---> 24\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemporal_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m              \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     eval_loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate([x_valid, temporal_valid], y_valid, \n\u001b[1;32m     28\u001b[0m                                batch_size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     29\u001b[0m patience \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 1\n",
    "time_unit = [0.5,1,2,3,4,6,8,12,24]\n",
    "# time_unit = [24]\n",
    "stamp_list = [int(2*i) for i in time_unit]\n",
    "step_list = [int(48/i) for i in stamp_list]\n",
    "lag_list = [2*(i+1) for i in range(12)]\n",
    "\n",
    "table = np.zeros(shape=(len(time_unit),len(lag_list)))\n",
    "for i in range(len(time_unit)): # time unit에 따라\n",
    "    for j in range(len(lag_list)): # lag에 따라\n",
    "        print(f'STAMP={stamp_list[i]}, LAG={lag_list[j]}, STEP={step_list[i]}')\n",
    "        try:\n",
    "            table[i,j] = multi_step_forecast(STAMP=stamp_list[i], LAG=lag_list[j], STEP=step_list[i])\n",
    "        except:\n",
    "            train(STAMP=stamp_list[i], LAG=lag_list[j], STEP=step_list[i])\n",
    "            table[i,j] = multi_step_forecast(STAMP=stamp_list[i], LAG=lag_list[j], STEP=step_list[i])\n",
    "        print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bf0ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = ['lag_'+str(i) for i in lag_list]\n",
    "index = [stamp_list, time_unit, step_list]\n",
    "rmse_table = pd.DataFrame(table, columns=col_name, index=index)\n",
    "display(rmse_table)\n",
    "rmse_table.to_csv(f'rmse_table_recursive.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e887225d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
