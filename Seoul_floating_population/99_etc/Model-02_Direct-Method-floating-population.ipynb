{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff71f269",
   "metadata": {},
   "source": [
    "# Direct Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef9e6a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import random\n",
    "import math\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Conv2D, AveragePooling2D, Conv2DTranspose, Activation\n",
    "from keras.layers import concatenate, BatchNormalization, Dropout, Add, RepeatVector, Reshape\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "#from tensorflow.keras.optimizers import SGD , Adam\n",
    "from keras.optimizers import SGD , Adam\n",
    "# from keras.utils.training_utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9382dd3",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "985c1986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='')\n",
    "\n",
    "parser.add_argument('--lr', type=float, default=0.01)\n",
    "parser.add_argument('--decay', type=float, default=0.01)\n",
    "parser.add_argument('--batch', type=int, default=128)\n",
    "parser.add_argument('--epoch', type=int, default=10000)\n",
    "parser.add_argument('--drop_p', type=float, default=0.1)\n",
    "parser.add_argument('--reg', type=float, default=0.0)\n",
    "parser.add_argument('--test', action='store_true')\n",
    "\n",
    "parser.add_argument('--output_dir', type=str, default='./output/')\n",
    "parser.add_argument('--save_dir', type=str, default='./model_saved/')\n",
    "parser.add_argument('--model_name', type=str, default='no_named')\n",
    "\n",
    "parser.add_argument('--scale', type=str, default='min_max')\n",
    "parser.add_argument('--dataset_name', type=str, default='NYC')\n",
    "parser.add_argument('--thr', type=int, default=10)\n",
    "parser.add_argument('--alpha', type=float, default=0.05)\n",
    "parser.add_argument('--num_gpu', type=int, default=1)\n",
    "# parser.add_argument('--coord', type=float, default=25.0)\n",
    "# parser.add_argument('--coord_net', type=int, default=2)\n",
    "\n",
    "parser.add_argument('--temp', type=int, default=16)\n",
    "parser.add_argument('--nf', type=int, default=32)\n",
    "parser.add_argument('--enf', type=int, default=64)\n",
    "parser.add_argument('--patience', type=int, default=150)\n",
    "parser.add_argument('--es', type=str, default='min')\n",
    "\n",
    "args, extras = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a879d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.epoch = 10000\n",
    "args.num_gpu = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df60659",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ea7719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_np_data(filename):\n",
    "    try:\n",
    "        data = np.load(filename)['arr_0']\n",
    "        print(\"[*] Success to load \", filename)\n",
    "        return data\n",
    "    except:\n",
    "        raise IOError(\"Fail to load data\", filename)\n",
    "\n",
    "def get_min_max(data, scale='min_max'):\n",
    "    if scale=='min_max':\n",
    "        return np.min(data), np.max(data)\n",
    "    else:\n",
    "        return None, None\n",
    "    \n",
    "def min_max(data, min_value, max_value):\n",
    "    result = data - min_value\n",
    "    scale = max_value - min_value\n",
    "    assert scale > 0\n",
    "    result = result/scale\n",
    "    return result\n",
    "\n",
    "def scaler(data, scale_type='log', inv=False, min_value=None, max_value=None):\n",
    "    if scale_type == 'log':\n",
    "        if not inv:\n",
    "            print(\"[*] \", np.shape(data), \":log scaled\")\n",
    "            return logscale(data)\n",
    "        else:\n",
    "            print(\"[*] \", np.shape(data), \": inverse log scaled\")\n",
    "            return inverse_logscale(data)\n",
    "    elif scale_type == 'min_max':\n",
    "        assert (min_value != None) and (max_value != None)\n",
    "        if not inv:\n",
    "            return min_max(data, min_value, max_value)\n",
    "        else:\n",
    "            return inverse_min_max(data, min_value, max_value)\n",
    "    else:\n",
    "        print(\"[!] invalid scale type: \", scale_type)\n",
    "        raise\n",
    "        \n",
    "def inverse_min_max(data, min_value, max_value):\n",
    "    scale = max_value - min_value\n",
    "    result = scale * data + min_value\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00ffb6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadData(STAMP, LAG, STEP, train=True, valid=False):\n",
    "    \n",
    "#     args.model_name = f'SeoulFloatingPop_lag{LAG}_step{STEP}'\n",
    "\n",
    "    ### train set\n",
    "\n",
    "    x_train = load_np_data(f'./data/x_train_stamp{STAMP}_lag{LAG}_step{STEP}_v2.npz')\n",
    "    min_x, max_x = get_min_max(x_train, 'min_max')\n",
    "\n",
    "    if train:    \n",
    "        y_train = load_np_data(f'./data/y_train_stamp{STAMP}_lag{LAG}_step{STEP}_v2.npz')\n",
    "        temporal_train = load_np_data(f'./data/temporal_train_stamp{STAMP}_lag{LAG}_step{STEP}_v2.npz')\n",
    "        temporal_train = temporal_train.reshape(temporal_train.shape[0],temporal_train.shape[2])\n",
    "        \n",
    "        # Min Max Scaling\n",
    "        x_train = scaler(x_train, 'min_max', inv=False, min_value=min_x, max_value=max_x)\n",
    "        y_train = scaler(y_train, 'min_max', inv=False, min_value=min_x, max_value=max_x)\n",
    "        \n",
    "        ### validation set\n",
    "        valid_ratio=0.2\n",
    "        num_train = int(len(x_train)*(1.0-valid_ratio))\n",
    "        x_train, x_valid = x_train[:num_train], x_train[num_train:]\n",
    "        temporal_train, temporal_valid = temporal_train[:num_train], temporal_train[num_train:]\n",
    "        y_train, y_valid = y_train[:num_train], y_train[num_train:]\n",
    "        \n",
    "        if valid:\n",
    "            \n",
    "            print(f'x_valid.shape = {x_valid.shape}')\n",
    "            print(f'y_valid.shape = {y_valid.shape}')\n",
    "            print(f'temporal_valid.shape = {temporal_valid.shape}')\n",
    "        \n",
    "            return x_valid, temporal_valid, y_valid\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            print('--- training dataset ---')\n",
    "            print(f'x_train.shape = {x_train.shape}')\n",
    "            print(f'y_train.shape = {y_train.shape}')\n",
    "            print(f'temporal_train.shape = {temporal_train.shape}')\n",
    "\n",
    "            return x_train, temporal_train, y_train\n",
    "    \n",
    "    else: ### test set\n",
    "\n",
    "        x_test = load_np_data(f'./data/x_test_stamp{STAMP}_lag{LAG}_step{STEP}_v2.npz')\n",
    "        y_test = load_np_data(f'./data/y_test_stamp{STAMP}_lag{LAG}_step{STEP}_v2.npz')\n",
    "        temporal_test = load_np_data(f'./data/temporal_test_stamp{STAMP}_lag{LAG}_step{STEP}_v2.npz')\n",
    "\n",
    "        # Min Max Scaling\n",
    "        x_test = scaler(x_test, 'min_max', inv=False, min_value=min_x, max_value=max_x)\n",
    "        y_test = scaler(y_test, 'min_max', inv=False, min_value=min_x, max_value=max_x)\n",
    "\n",
    "        print('--- test dataset ---')\n",
    "        print(f'x_test.shape = {x_test.shape}')\n",
    "        print(f'y_test.shape = {y_test.shape}')\n",
    "        print(f'temporal_test.shape = {temporal_test.shape}')\n",
    "\n",
    "        return x_test, temporal_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aed9907",
   "metadata": {},
   "source": [
    "# TGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "343db561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    rtn = np.sqrt(  np.average( np.square(y_pred-y_true) ) )\n",
    "    return  rtn\n",
    "\n",
    "def mape(y_true,y_pred):\n",
    "    rtn = np.mean(np.abs((y_true - y_pred) / (1.0+y_true)))\n",
    "    return rtn\n",
    "\n",
    "def mape_trs(y_true,y_pred, trs=0):\n",
    "    true_mask = y_true > trs\n",
    "    tmp_abs = np.divide(np.abs(y_true-y_pred)[true_mask] , y_true[true_mask])\n",
    "\n",
    "    rtn = (np.average(tmp_abs))\n",
    "    return rtn\n",
    "\n",
    "def rmse_trs(y_true,y_pred, trs=0):\n",
    "    true_mask = y_true > trs\n",
    "    tmp_abs = np.sqrt(np.average(np.square(y_pred-y_true)[true_mask]))\n",
    "    return tmp_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10ce0634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gn_block(input, num_c=64, kernel_size=(3,3), strides=(1,1), padding='SAME', activation='relu', dropout=None, regularizer=0.01):\n",
    "    net = AveragePooling2D(kernel_size, strides, padding)(input)\n",
    "    net = Conv2D(num_c, kernel_size=(1,1), strides=strides, activation='linear', padding=padding, kernel_regularizer=regularizers.l1(regularizer))(net)\n",
    "\n",
    "    net_sf = Conv2D(num_c, kernel_size=(1,1), strides=strides, activation='linear', padding=padding, kernel_regularizer=regularizers.l1(regularizer))(input)\n",
    "\n",
    "    net = Add()([net, net_sf])\n",
    "    net = concatenate([input, net])\n",
    "    net = Conv2D(num_c, kernel_size=(1,1), strides=strides, activation=activation, padding=padding, kernel_regularizer=regularizers.l1(regularizer))(net)\n",
    "    net = BatchNormalization()(net)\n",
    "\n",
    "    if dropout == None:\n",
    "        return net\n",
    "    else:\n",
    "        net = Dropout(dropout)(net)\n",
    "        return net\n",
    "\n",
    "def deconv_block(input, num_c=64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', dropout=None, regularizer=0.01):\n",
    "    net = Conv2DTranspose(num_c, kernel_size=kernel_size, strides=strides, activation=activation, padding=padding, kernel_regularizer=regularizers.l1(regularizer))(input)\n",
    "    net = BatchNormalization()(net)\n",
    "    if dropout == None:\n",
    "        return net\n",
    "    else:\n",
    "        net = Dropout(dropout)(net)\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "277b5465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TGNet(input_shape):\n",
    "    nf = args.nf\n",
    "    h,w = input_shape[:2]\n",
    "    start_input = Input(shape=input_shape)\n",
    "    temporal_input = Input(shape=(55,))\n",
    "    input_tensors = [start_input, temporal_input]\n",
    "\n",
    "\n",
    "    ### Temporal guided embedding\n",
    "    net_temp = Dense(args.temp, activation='relu')(temporal_input)\n",
    "    # self.net_temp = Dense(args.temp, activation='relu')(net_temp)\n",
    "    net_temp = RepeatVector(h*w)(net_temp)\n",
    "    net_temp = Reshape((h,w,args.temp))(net_temp)\n",
    "\n",
    "    ### U-net layers\n",
    "    net1 = concatenate([start_input, net_temp], axis=-1)\n",
    "    net1 = gn_block(net1, nf, dropout=args.drop_p,regularizer=args.reg)\n",
    "    net11 = AveragePooling2D(pool_size=(2,2))(net1)\n",
    "    net2 = gn_block(net11, nf*2,  dropout=args.drop_p, regularizer=args.reg)\n",
    "    net3 = gn_block(net2, nf*2,  dropout=args.drop_p, regularizer=args.reg)\n",
    "    net33 = concatenate([net2, net3])\n",
    "    net4 = gn_block(net33, nf*2,  dropout=args.drop_p, regularizer=args.reg)\n",
    "    net4 = concatenate([net2, net3, net4])\n",
    "\n",
    "    net5 = deconv_block(net4, nf*4, (2,2), (2,2),   dropout=args.drop_p,regularizer=args.reg)\n",
    "    net5 = concatenate([net5, net1])\n",
    "    net6 = deconv_block(net5, nf*4, (3,3), (1,1), 'same',  dropout=args.drop_p, regularizer=args.reg)\n",
    "\n",
    "    ## Position-wise Regression\n",
    "    net7 = concatenate([net6, start_input, net_temp], axis=-1)\n",
    "    net7 = gn_block(net7, nf*4, kernel_size=(1,1), dropout=args.drop_p, regularizer=args.reg)\n",
    "\n",
    "    output = Conv2D(1, kernel_size=(1,1), padding='same', kernel_regularizer=regularizers.l2(args.reg))(net7)\n",
    "    output = Activation('relu')(output)\n",
    "\n",
    "    model = Model(inputs=input_tensors, outputs=output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ce14749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(STAMP, LAG, STEP):\n",
    "\n",
    "    x_train, temporal_train, y_train = LoadData(STAMP=STAMP, LAG=LAG, STEP=STEP, train=True, valid=False)\n",
    "    x_valid, temporal_valid, y_valid = LoadData(STAMP=STAMP, LAG=LAG, STEP=STEP, train=True, valid=True)\n",
    "\n",
    "    input_shape = [10, 20, LAG]\n",
    "    model = TGNet(input_shape)\n",
    "\n",
    "    model.compile(loss=['mean_absolute_error'], \n",
    "               optimizer=Adam(lr=0.001, decay=args.decay), \n",
    "               metrics=['mean_absolute_error'])\n",
    "\n",
    "    \n",
    "    print('===== START TRAINGING =====')\n",
    "    \n",
    "    best_eval_loss = 100000\n",
    "    patience = 0\n",
    "\n",
    "    for idx in range(args.epoch): # epoch\n",
    "        if idx%100 == 0:\n",
    "            print(f'Epoch = {idx}')\n",
    "            \n",
    "        with tf.device(f'/GPU:{args.num_gpu}'):\n",
    "            model.fit([x_train, temporal_train], y_train, \n",
    "                  batch_size=args.batch, epochs=1, shuffle=True,verbose=0)\n",
    "\n",
    "            eval_loss = model.evaluate([x_valid, temporal_valid], y_valid, \n",
    "                                   batch_size=args.batch, verbose=0)\n",
    "        patience += 1\n",
    "        if patience > args.patience:\n",
    "            print(f'Epoch = {idx}, patience reached {args.patience}')\n",
    "            break\n",
    "\n",
    "        if best_eval_loss > eval_loss[-1]:\n",
    "            if not os.path.exists('./model_saved'):\n",
    "                os.mkdir('./model_saved')\n",
    "            else:\n",
    "                model.save(f'./model_saved/best_model_stamp{STAMP}_lag{LAG}_step{STEP}_v2.h5')\n",
    "\n",
    "            best_eval_loss = eval_loss[-1]\n",
    "            patience = 0\n",
    "    print('===== END TRAINGING =====')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb0856a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_result(data):\n",
    "    num_row, h, w = data.shape[:3]\n",
    "    num_col = int(h*w)\n",
    "    return np.reshape(data, [num_row, num_col])\n",
    "\n",
    "def save_test_output(pred_inverse, y_inverse, output_path=None):\n",
    "    num_row, h, w = pred_inverse.shape[:3]\n",
    "    num_col = int(h*w)\n",
    "    assert pred_inverse.shape[:3] == y_inverse.shape[:3]\n",
    "    if output_path == None:\n",
    "        output_path = './model_output/temporal_directory'\n",
    "        print(\"[!] Please Assign Output Path in Arguments\")\n",
    "\n",
    "    np_pred = flatten_result(pred_inverse) #np.reshape(pred_inverse, [num_row, num_col])\n",
    "    np_y = flatten_result(y_inverse) #np.reshape(y_inverse, [num_row, num_col])\n",
    "\n",
    "    col_name = ['col_'+str(i) for i in range(0, num_col)]\n",
    "    index = np.arange(0, num_row)\n",
    "    df_pred = pd.DataFrame(np_pred, columns=col_name, index=index)\n",
    "    df_y = pd.DataFrame(np_y, columns=col_name, index=index)\n",
    "\n",
    "    df_y.to_csv(output_path+'_gt_v2.csv', index=False)\n",
    "    df_pred.to_csv(output_path+'_pred_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c6b1b0",
   "metadata": {},
   "source": [
    "# Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93b4665a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_step_forecast(STAMP, LAG, STEP):\n",
    "    # Load saved model\n",
    "    with tf.device(f'/GPU:{args.num_gpu}'):\n",
    "        model = tf.keras.models.load_model(f'./model_saved/best_model_stamp{STAMP}_lag{LAG}_step{STEP}_v2.h5')\n",
    "    \n",
    "    min_x, max_x = get_min_max(load_np_data(f'./data/x_train_stamp{STAMP}_lag{LAG}_step{STEP}_v2.npz'), 'min_max')\n",
    "    x_test, temporal_test, y_test = LoadData(STAMP=STAMP, LAG=LAG, STEP=STEP, train=False, valid=False)\n",
    "    \n",
    "    temporal_test_step1 = temporal_test[:,0,:]\n",
    "    with tf.device(f'/GPU:{args.num_gpu}'):\n",
    "        y_pred =  model.predict([x_test, temporal_test_step1])\n",
    "    y_true = np.expand_dims(y_test[:,:,:,0], axis=-1)\n",
    "    y_pred_inv = scaler(y_pred, 'min_max', inv=True, min_value=min_x, max_value=max_x)\n",
    "    y_true_inv = scaler(y_true, 'min_max', inv=True, min_value=min_x, max_value=max_x)    \n",
    "    save_test_output(y_pred_inv, y_true_inv, output_path=f'./output/predictions/stamp{STAMP}_lag{LAG}_step{STEP}_v2')\n",
    "    RMSE = rmse(y_true_inv, y_pred_inv)\n",
    "    print('#'*57)\n",
    "    print(f'###  RMSE of STAMP {STAMP} LAG {LAG} STEP {STEP} = {RMSE} ###')\n",
    "    print('#'*57)\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32427836",
   "metadata": {},
   "source": [
    "# 24H ahead forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e322a5",
   "metadata": {},
   "source": [
    "### Tuning the time unit of training data (Direct Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20c4e7c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAMP=1, LAG=2, STEP=48\n",
      "[*] Success to load  ./data/x_train_stamp1_lag2_step48_v2.npz\n",
      "[*] Success to load  ./data/y_train_stamp1_lag2_step48_v2.npz\n",
      "[*] Success to load  ./data/temporal_train_stamp1_lag2_step48_v2.npz\n",
      "--- training dataset ---\n",
      "x_train.shape = (3416, 10, 20, 2)\n",
      "y_train.shape = (3416, 10, 20, 1)\n",
      "temporal_train.shape = (3416, 55)\n",
      "[*] Success to load  ./data/x_train_stamp1_lag2_step48_v2.npz\n",
      "[*] Success to load  ./data/y_train_stamp1_lag2_step48_v2.npz\n",
      "[*] Success to load  ./data/temporal_train_stamp1_lag2_step48_v2.npz\n",
      "x_valid.shape = (854, 10, 20, 2)\n",
      "y_valid.shape = (854, 10, 20, 1)\n",
      "temporal_valid.shape = (854, 55)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-28 01:20:28.768808: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-28 01:20:30.109027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 888 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:03:00.0, compute capability: 7.5\n",
      "2022-10-28 01:20:30.110308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 9020 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:05:00.0, compute capability: 7.5\n",
      "/home/jpark/miniconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== START TRAINGING =====\n",
      "Epoch = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-28 01:20:34.511513: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n",
      "2022-10-28 01:20:35.360073: E tensorflow/stream_executor/gpu/asm_compiler.cc:105] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n",
      "\n",
      "You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-10-28 01:20:35.423769: W tensorflow/stream_executor/gpu/asm_compiler.cc:230] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 7.5\n",
      "2022-10-28 01:20:35.423808: W tensorflow/stream_executor/gpu/asm_compiler.cc:233] Used ptxas at ptxas\n",
      "2022-10-28 01:20:35.423936: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2022-10-28 01:20:38.353294: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2022-10-28 01:20:38.353343: W ./tensorflow/stream_executor/stream.h:2119] attempting to perform DNN operation using StreamExecutor without DNN support\n",
      "2022-10-28 01:20:38.367130: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2022-10-28 01:20:38.367193: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:1130 : UNIMPLEMENTED: DNN library is not found.\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/average_pooling2d/AvgPool' defined at (most recent call last):\n    File \"/home/jpark/miniconda3/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/jpark/miniconda3/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/jpark/miniconda3/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/home/jpark/miniconda3/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/home/jpark/miniconda3/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_4363/899986511.py\", line 14, in <cell line: 8>\n      train(STAMP=stamp_list[i], LAG=lag_list[j], STEP=step_list[i])\n    File \"/tmp/ipykernel_4363/3568112244.py\", line 27, in train\n      eval_loss = model.evaluate([x_valid, temporal_valid], y_valid,\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1756, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1557, in test_function\n      return step_function(self, iterator)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1546, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1535, in run_step\n      outputs = model.test_step(data)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1499, in test_step\n      y_pred = self(x, training=False)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/layers/pooling/base_pooling2d.py\", line 73, in call\n      outputs = self.pool_function(\nNode: 'model/average_pooling2d/AvgPool'\nDetected at node 'model/average_pooling2d/AvgPool' defined at (most recent call last):\n    File \"/home/jpark/miniconda3/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/jpark/miniconda3/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/jpark/miniconda3/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/home/jpark/miniconda3/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/home/jpark/miniconda3/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_4363/899986511.py\", line 14, in <cell line: 8>\n      train(STAMP=stamp_list[i], LAG=lag_list[j], STEP=step_list[i])\n    File \"/tmp/ipykernel_4363/3568112244.py\", line 27, in train\n      eval_loss = model.evaluate([x_valid, temporal_valid], y_valid,\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1756, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1557, in test_function\n      return step_function(self, iterator)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1546, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1535, in run_step\n      outputs = model.test_step(data)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1499, in test_step\n      y_pred = self(x, training=False)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/layers/pooling/base_pooling2d.py\", line 73, in call\n      outputs = self.pool_function(\nNode: 'model/average_pooling2d/AvgPool'\n2 root error(s) found.\n  (0) INTERNAL:  dnn PoolForward launch failed\n\t [[{{node model/average_pooling2d/AvgPool}}]]\n\t [[mean_absolute_error/weighted_loss/Sum/_12]]\n  (1) INTERNAL:  dnn PoolForward launch failed\n\t [[{{node model/average_pooling2d/AvgPool}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_test_function_5110]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     table[i,j] \u001b[38;5;241m=\u001b[39m single_step_forecast(STAMP\u001b[38;5;241m=\u001b[39mstamp_list[i], LAG\u001b[38;5;241m=\u001b[39mlag_list[j], STEP\u001b[38;5;241m=\u001b[39mstep_list[i])\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSTAMP\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstamp_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLAG\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlag_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSTEP\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     table[i,j] \u001b[38;5;241m=\u001b[39m single_step_forecast(STAMP\u001b[38;5;241m=\u001b[39mstamp_list[i], LAG\u001b[38;5;241m=\u001b[39mlag_list[j], STEP\u001b[38;5;241m=\u001b[39mstep_list[i])\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(table)\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(STAMP, LAG, STEP)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/GPU:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mnum_gpu\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     24\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit([x_train, temporal_train], y_train, \n\u001b[1;32m     25\u001b[0m           batch_size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m eval_loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemporal_valid\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m patience \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m patience \u001b[38;5;241m>\u001b[39m args\u001b[38;5;241m.\u001b[39mpatience:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node 'model/average_pooling2d/AvgPool' defined at (most recent call last):\n    File \"/home/jpark/miniconda3/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/jpark/miniconda3/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/jpark/miniconda3/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/home/jpark/miniconda3/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/home/jpark/miniconda3/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_4363/899986511.py\", line 14, in <cell line: 8>\n      train(STAMP=stamp_list[i], LAG=lag_list[j], STEP=step_list[i])\n    File \"/tmp/ipykernel_4363/3568112244.py\", line 27, in train\n      eval_loss = model.evaluate([x_valid, temporal_valid], y_valid,\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1756, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1557, in test_function\n      return step_function(self, iterator)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1546, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1535, in run_step\n      outputs = model.test_step(data)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1499, in test_step\n      y_pred = self(x, training=False)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/layers/pooling/base_pooling2d.py\", line 73, in call\n      outputs = self.pool_function(\nNode: 'model/average_pooling2d/AvgPool'\nDetected at node 'model/average_pooling2d/AvgPool' defined at (most recent call last):\n    File \"/home/jpark/miniconda3/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/jpark/miniconda3/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/jpark/miniconda3/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/home/jpark/miniconda3/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/home/jpark/miniconda3/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_4363/899986511.py\", line 14, in <cell line: 8>\n      train(STAMP=stamp_list[i], LAG=lag_list[j], STEP=step_list[i])\n    File \"/tmp/ipykernel_4363/3568112244.py\", line 27, in train\n      eval_loss = model.evaluate([x_valid, temporal_valid], y_valid,\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1756, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1557, in test_function\n      return step_function(self, iterator)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1546, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1535, in run_step\n      outputs = model.test_step(data)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1499, in test_step\n      y_pred = self(x, training=False)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/jpark/miniconda3/lib/python3.8/site-packages/keras/layers/pooling/base_pooling2d.py\", line 73, in call\n      outputs = self.pool_function(\nNode: 'model/average_pooling2d/AvgPool'\n2 root error(s) found.\n  (0) INTERNAL:  dnn PoolForward launch failed\n\t [[{{node model/average_pooling2d/AvgPool}}]]\n\t [[mean_absolute_error/weighted_loss/Sum/_12]]\n  (1) INTERNAL:  dnn PoolForward launch failed\n\t [[{{node model/average_pooling2d/AvgPool}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_test_function_5110]"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "time_unit = [0.5,1,2,3,4,6,8,12,24]\n",
    "stamp_list = [int(2*i) for i in time_unit]\n",
    "step_list = [int(48/i) for i in stamp_list]\n",
    "lag_list = [2*(i+1) for i in range(12)]\n",
    "\n",
    "table = np.zeros(shape=(len(time_unit),len(lag_list)))\n",
    "for i in range(len(time_unit)): # time unit \n",
    "    for j in range(len(lag_list)): # lag \n",
    "        print(f'STAMP={stamp_list[i]}, LAG={lag_list[j]}, STEP={step_list[i]}')\n",
    "        try:\n",
    "            table[i,j] = single_step_forecast(STAMP=stamp_list[i], LAG=lag_list[j], STEP=step_list[i])\n",
    "        except:\n",
    "            train(STAMP=stamp_list[i], LAG=lag_list[j], STEP=step_list[i])\n",
    "            table[i,j] = single_step_forecast(STAMP=stamp_list[i], LAG=lag_list[j], STEP=step_list[i])\n",
    "        print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62057f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = ['lag_'+str(i) for i in lag_list]\n",
    "index = [stamp_list, time_unit, step_list]\n",
    "rmse_table = pd.DataFrame(table, columns=col_name, index=index)\n",
    "display(rmse_table)\n",
    "rmse_table.to_csv(f'rmse_table_direct.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
